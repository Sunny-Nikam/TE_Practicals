{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1xijDd0OOcsBHmm7ZJWRs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"EWGpAH6ZGdUN","executionInfo":{"status":"ok","timestamp":1682588754091,"user_tz":-330,"elapsed":10,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}}},"outputs":[],"source":["sentence1 = \"I will walk 500 miles and I would walk 500 more. Just to be the man who walks \" + \\\n","            \"a thousand miles to fall down at your door!\"\n","sentence2 = \"I played the play playfully as the players were playing in the play with playfullness\""]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","\n","from nltk import word_tokenize, sent_tokenize\n","\n","print('Tokenized words:', word_tokenize(sentence1))\n","print('\\nTokenized sentences:', sent_tokenize(sentence1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPShMJcnGulw","executionInfo":{"status":"ok","timestamp":1682589052657,"user_tz":-330,"elapsed":1498,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}},"outputId":"3ca51cbd-fb35-4ec7-b094-64c05a5264f1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Tokenized words: ['I', 'will', 'walk', '500', 'miles', 'and', 'I', 'would', 'walk', '500', 'more', '.', 'Just', 'to', 'be', 'the', 'man', 'who', 'walks', 'a', 'thousand', 'miles', 'to', 'fall', 'down', 'at', 'your', 'door', '!']\n","\n","Tokenized sentences: ['I will walk 500 miles and I would walk 500 more.', 'Just to be the man who walks a thousand miles to fall down at your door!']\n"]}]},{"cell_type":"code","source":["from nltk import pos_tag\n","import nltk\n","nltk.download('averaged_perceptron_tagger')\n","\n","token = word_tokenize(sentence1) + word_tokenize(sentence2)\n","tagged = pos_tag(token)                 \n","\n","print(\"Tagging Parts of Speech:\", tagged)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"evpgGMnNH2WJ","executionInfo":{"status":"ok","timestamp":1682589507591,"user_tz":-330,"elapsed":9,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}},"outputId":"df7d2a77-59aa-447d-a936-d9b889d76db2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Tagging Parts of Speech: [('I', 'PRP'), ('will', 'MD'), ('walk', 'VB'), ('500', 'CD'), ('miles', 'NNS'), ('and', 'CC'), ('I', 'PRP'), ('would', 'MD'), ('walk', 'VB'), ('500', 'CD'), ('more', 'JJR'), ('.', '.'), ('Just', 'NNP'), ('to', 'TO'), ('be', 'VB'), ('the', 'DT'), ('man', 'NN'), ('who', 'WP'), ('walks', 'VBZ'), ('a', 'DT'), ('thousand', 'NN'), ('miles', 'NNS'), ('to', 'TO'), ('fall', 'VB'), ('down', 'RP'), ('at', 'IN'), ('your', 'PRP$'), ('door', 'NN'), ('!', '.'), ('I', 'PRP'), ('played', 'VBD'), ('the', 'DT'), ('play', 'NN'), ('playfully', 'RB'), ('as', 'IN'), ('the', 'DT'), ('players', 'NNS'), ('were', 'VBD'), ('playing', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('play', 'NN'), ('with', 'IN'), ('playfullness', 'NN')]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","\n","from nltk import word_tokenize, sent_tokenize\n","\n","print('Tokenized words:', word_tokenize(sentence1))\n","print('\\nTokenized sentences:', sent_tokenize(sentence1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682589264176,"user_tz":-330,"elapsed":480,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}},"outputId":"9b3df161-8e78-48ab-eeef-dfc9e28613c8","id":"xLU4f7KbIoxZ"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized words: ['I', 'will', 'walk', '500', 'miles', 'and', 'I', 'would', 'walk', '500', 'more', '.', 'Just', 'to', 'be', 'the', 'man', 'who', 'walks', 'a', 'thousand', 'miles', 'to', 'fall', 'down', 'at', 'your', 'door', '!']\n","\n","Tokenized sentences: ['I will walk 500 miles and I would walk 500 more.', 'Just to be the man who walks a thousand miles to fall down at your door!']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","\n","from nltk import pos_tag\n","\n","token = word_tokenize(sentence1) + word_tokenize(sentence2)\n","tagged = pos_tag(token)                 \n","\n","print(\"Tagging Parts of Speech:\", tagged)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFYFxh76IsH_","executionInfo":{"status":"ok","timestamp":1682589450746,"user_tz":-330,"elapsed":1155,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}},"outputId":"e78a740e-2b8a-4655-d740-00570f9a5dab"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Tagging Parts of Speech: [('I', 'PRP'), ('will', 'MD'), ('walk', 'VB'), ('500', 'CD'), ('miles', 'NNS'), ('and', 'CC'), ('I', 'PRP'), ('would', 'MD'), ('walk', 'VB'), ('500', 'CD'), ('more', 'JJR'), ('.', '.'), ('Just', 'NNP'), ('to', 'TO'), ('be', 'VB'), ('the', 'DT'), ('man', 'NN'), ('who', 'WP'), ('walks', 'VBZ'), ('a', 'DT'), ('thousand', 'NN'), ('miles', 'NNS'), ('to', 'TO'), ('fall', 'VB'), ('down', 'RP'), ('at', 'IN'), ('your', 'PRP$'), ('door', 'NN'), ('!', '.'), ('I', 'PRP'), ('played', 'VBD'), ('the', 'DT'), ('play', 'NN'), ('playfully', 'RB'), ('as', 'IN'), ('the', 'DT'), ('players', 'NNS'), ('were', 'VBD'), ('playing', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('play', 'NN'), ('with', 'IN'), ('playfullness', 'NN')]\n"]}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')\n"," \n","stop_words = stopwords.words('english')\n","\n","token = word_tokenize(sentence1)\n","cleaned_token = []\n","\n","for word in token:\n","    if word not in stop_words:\n","        cleaned_token.append(word)\n","\n","print('Unclean version:', token)\n","print('\\nCleaned version:', cleaned_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEFtKRD7JXjK","executionInfo":{"status":"ok","timestamp":1682589627863,"user_tz":-330,"elapsed":520,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}},"outputId":"4cb87471-7e20-4cb7-81f3-9788f2245df4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Unclean version: ['I', 'will', 'walk', '500', 'miles', 'and', 'I', 'would', 'walk', '500', 'more', '.', 'Just', 'to', 'be', 'the', 'man', 'who', 'walks', 'a', 'thousand', 'miles', 'to', 'fall', 'down', 'at', 'your', 'door', '!']\n","\n","Cleaned version: ['I', 'walk', '500', 'miles', 'I', 'would', 'walk', '500', '.', 'Just', 'man', 'walks', 'thousand', 'miles', 'fall', 'door', '!']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","\n","stemmer = PorterStemmer()\n","\n","token = word_tokenize(sentence2)\n","\n","stemmed = [stemmer.stem(word) for word in token]\n","print(\" \".join(stemmed))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Gz9WgLjKETl","executionInfo":{"status":"ok","timestamp":1682589644963,"user_tz":-330,"elapsed":516,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}},"outputId":"82a69657-cb99-4b6b-a87f-20ba6cbc8ba4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["i play the play play as the player were play in the play with playful\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer \n","nltk.download('wordnet')\n","lemmatizer = WordNetLemmatizer()\n","\n","token = word_tokenize(sentence2)\n","\n","lemmatized_output = [lemmatizer.lemmatize(word) for word in token]\n","print(\" \".join(lemmatized_output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9QQ8ljGXKIIX","executionInfo":{"status":"ok","timestamp":1682589702919,"user_tz":-330,"elapsed":3053,"user":{"displayName":"Siddhi Mane","userId":"05473406478203348157"}},"outputId":"d13e9392-c4ee-4cc9-986e-35949ba0bd00"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["I played the play playfully a the player were playing in the play with playfullness\n"]}]}]}